{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## MFCC on noise only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_pad_len = 174\n",
    "\n",
    "def extract_features(file_name):\n",
    "   \n",
    "    try:\n",
    "        audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast') \n",
    "        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "        pad_width = max_pad_len - mfccs.shape[1]\n",
    "        mfccs = np.pad(mfccs, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(\"Error encountered while parsing file: \", file_name)\n",
    "        return None \n",
    "     \n",
    "    return mfccs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "5000\n",
      "5100\n",
      "5200\n",
      "5300\n",
      "5400\n",
      "5500\n",
      "5600\n",
      "5700\n",
      "5800\n",
      "5900\n",
      "6000\n",
      "6100\n",
      "6200\n",
      "6300\n",
      "6400\n",
      "6500\n",
      "6600\n",
      "6700\n",
      "6800\n",
      "6900\n",
      "7000\n",
      "7100\n",
      "7200\n",
      "7300\n",
      "7400\n",
      "7500\n",
      "7600\n",
      "7700\n",
      "7800\n",
      "7900\n",
      "8000\n",
      "8100\n",
      "8200\n",
      "8300\n",
      "8400\n",
      "8500\n",
      "8600\n",
      "8700\n",
      "Finished feature extraction from  8732  files\n"
     ]
    }
   ],
   "source": [
    "# Set the path to the full UrbanSound dataset \n",
    "fulldatasetpath = 'UrbanSound8K/audio/'\n",
    "\n",
    "metadata = pd.read_csv('UrbanSound8K/metadata/UrbanSound8K.csv')\n",
    "\n",
    "features = []\n",
    "\n",
    "# Iterate through each sound file and extract the features \n",
    "counter = 0\n",
    "for index, row in metadata.iterrows():    \n",
    "    file_name = fulldatasetpath +'fold'+str(row[\"fold\"])+'/'+str(row[\"slice_file_name\"])\n",
    "    \n",
    "    class_label = row[\"class\"]\n",
    "    data = extract_features(file_name)\n",
    "    \n",
    "    features.append([data, class_label])\n",
    "    if counter % 100 == 0:\n",
    "        print(counter)\n",
    "    counter += 1\n",
    "\n",
    "# Convert into a Panda dataframe \n",
    "featuresdf = pd.DataFrame(features, columns=['feature','class_label'])\n",
    "\n",
    "print('Finished feature extraction from ', len(featuresdf), ' files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>class_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>[[-306.77255, -177.59209, -99.13616, -65.97198...</td>\n",
       "      <td>dog_bark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>[[-457.69534, -451.0248, -450.68613, -445.0000...</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>[[-468.0367, -467.42264, -481.04654, -486.5948...</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             feature       class_label\n",
       "0  [[-306.77255, -177.59209, -99.13616, -65.97198...          dog_bark\n",
       "1  [[-457.69534, -451.0248, -450.68613, -445.0000...  children_playing\n",
       "2  [[-468.0367, -467.42264, -481.04654, -486.5948...  children_playing"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featuresdf.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 174)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featuresdf['feature'][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_featuresdf = featuresdf.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# each value in feature is a (40,174) numpy array, in order to pass the data to Google Colab, it has to be saved as a .csv file. However, pd.to_csv ruins\n",
    "# the numpy format. What I did here is faltten the 2D numpy array to a list and convert the list to string with only number and comma\n",
    "# later in the Google Colab, read the data into dataframe and using numpy.fromstring convert it back to numpy array and reshape it back to (40,174), since\n",
    "# every original value has a fixed lenth, it won't cause any problem.\n",
    "\n",
    "# Disadvantage: the file is really large (1.12GB) compare the .to_csv directly (5MB+).\n",
    "\n",
    "test_featuresdf['new_feature'] = test_featuresdf.apply(lambda x: str(x['feature'].flatten().tolist()).strip('[]'),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_featuresdf = test_featuresdf[['new_feature','class_label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>new_feature</th>\n",
       "      <th>class_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-306.7725524902344, -177.5920867919922, -99.13...</td>\n",
       "      <td>dog_bark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-457.6953430175781, -451.0248107910156, -450.6...</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-468.0367126464844, -467.4226379394531, -481.0...</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         new_feature       class_label\n",
       "0  -306.7725524902344, -177.5920867919922, -99.13...          dog_bark\n",
       "1  -457.6953430175781, -451.0248107910156, -450.6...  children_playing\n",
       "2  -468.0367126464844, -467.4226379394531, -481.0...  children_playing"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_featuresdf.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_featuresdf.to_csv('mfcc_noise_only.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Combine my voice with noise and get the mfccs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_voice_array(noise,target_voice):\n",
    "    len_a = len(noise)\n",
    "    len_b = len(target_voice)\n",
    "    a = noise.copy()\n",
    "    b = target_voice.copy()\n",
    "    if len_a < len_b:\n",
    "        b[:len_a] += a\n",
    "        return (b / 2)\n",
    "    else:\n",
    "        a[:len_b] += b\n",
    "        return (a/ 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_pad_len = 222\n",
    "\n",
    "def extract_combined_features(file_name):\n",
    "    \n",
    "    try:\n",
    "        noise, noise_rate = librosa.load(file_name, res_type='kaiser_fast') \n",
    "        lower_coef = noise.max() / 0.07\n",
    "        noise = noise/lower_coef\n",
    "        \n",
    "        combined_voice = combine_voice_array(noise,my_voice)\n",
    "        \n",
    "        mfccs = librosa.feature.mfcc(y=combined_voice, sr=my_voice_rate, n_mfcc=40)\n",
    "        pad_width = max_pad_len - mfccs.shape[1]\n",
    "        mfccs = np.pad(mfccs, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(\"Error encountered while parsing file: \", file_name)\n",
    "        return None \n",
    "     \n",
    "    return mfccs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "Finished feature extraction from  8732  files\n"
     ]
    }
   ],
   "source": [
    "# Set the path to the full UrbanSound dataset \n",
    "fulldatasetpath = 'UrbanSound8K/audio/'\n",
    "\n",
    "metadata = pd.read_csv('UrbanSound8K/metadata/UrbanSound8K.csv')\n",
    "\n",
    "combined_voice_features = []\n",
    "\n",
    "my_voice,my_voice_rate = librosa.load('my_voice_sample.wav', res_type='kaiser_fast')\n",
    "\n",
    "# Iterate through each sound file and extract the features \n",
    "counter = 0\n",
    "for index, row in metadata.iterrows():    \n",
    "    file_name = fulldatasetpath +'fold'+str(row[\"fold\"])+'/'+str(row[\"slice_file_name\"])\n",
    "    \n",
    "    class_label = row[\"class\"]\n",
    "    data = extract_combined_features(file_name)\n",
    "    \n",
    "    combined_voice_features.append([data, class_label])\n",
    "    \n",
    "    \n",
    "    if counter % 1000 == 0:\n",
    "        print(counter)\n",
    "    counter += 1\n",
    "\n",
    "# Convert into a Panda dataframe \n",
    "combined_voice_features_df = pd.DataFrame(combined_voice_features, columns=['feature','class_label'])\n",
    "\n",
    "print('Finished feature extraction from ', len(featuresdf), ' files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>class_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>[[-615.8928, -501.51147, -418.0187, -379.61188...</td>\n",
       "      <td>dog_bark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>[[-431.9947, -425.3231, -423.77222, -418.19803...</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>[[-383.8137, -383.19577, -395.84634, -401.7457...</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             feature       class_label\n",
       "0  [[-615.8928, -501.51147, -418.0187, -379.61188...          dog_bark\n",
       "1  [[-431.9947, -425.3231, -423.77222, -418.19803...  children_playing\n",
       "2  [[-383.8137, -383.19577, -395.84634, -401.7457...  children_playing"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_voice_features_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_voice_features_df_temp = combined_voice_features_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_voice_features_df_temp['new_feature'] = combined_voice_features_df_temp.apply(lambda x: str(x['feature'].flatten().tolist()).strip('[]'),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_voice_features_df_temp = combined_voice_features_df_temp[['new_feature','class_label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>new_feature</th>\n",
       "      <th>class_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-615.892822265625, -501.511474609375, -418.018...</td>\n",
       "      <td>dog_bark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-431.99468994140625, -425.3230895996094, -423....</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-383.8136901855469, -383.1957702636719, -395.8...</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         new_feature       class_label\n",
       "0  -615.892822265625, -501.511474609375, -418.018...          dog_bark\n",
       "1  -431.99468994140625, -425.3230895996094, -423....  children_playing\n",
       "2  -383.8136901855469, -383.1957702636719, -395.8...  children_playing"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_voice_features_df_temp.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_voice_features_df_temp.to_csv('mfcc_combined_voice.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ZERO CROSSING rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_voice,my_voice_rate = librosa.load('my_voice_sample.wav', res_type='kaiser_fast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "mel_test = librosa.feature.melspectrogram(y=my_voice, sr=my_voice_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 222)"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mel_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_pad_len = 222\n",
    "\n",
    "def mel_extract_combined_features(file_name):\n",
    "    \n",
    "    try:\n",
    "        noise, noise_rate = librosa.load(file_name, res_type='kaiser_fast') \n",
    "        lower_coef = noise.max() / 0.07\n",
    "        noise = noise/lower_coef\n",
    "        \n",
    "        combined_voice = combine_voice_array(noise,my_voice)\n",
    "        \n",
    "        mel = librosa.feature.melspectrogram(y=combined_voice, sr=my_voice_rate)\n",
    "        pad_width = max_pad_len - mel.shape[1]\n",
    "        mel = np.pad(mel, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(\"Error encountered while parsing file: \", file_name)\n",
    "        return None \n",
    "     \n",
    "    return mel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "Finished feature extraction from  8732  files\n"
     ]
    }
   ],
   "source": [
    "# Set the path to the full UrbanSound dataset \n",
    "fulldatasetpath = 'UrbanSound8K/audio/'\n",
    "\n",
    "metadata = pd.read_csv('UrbanSound8K/metadata/UrbanSound8K.csv')\n",
    "\n",
    "combined_voice_features_mel = []\n",
    "\n",
    "my_voice,my_voice_rate = librosa.load('my_voice_sample.wav', res_type='kaiser_fast')\n",
    "\n",
    "# Iterate through each sound file and extract the features \n",
    "counter = 0\n",
    "for index, row in metadata.iterrows():    \n",
    "    file_name = fulldatasetpath +'fold'+str(row[\"fold\"])+'/'+str(row[\"slice_file_name\"])\n",
    "    \n",
    "    class_label = row[\"class\"]\n",
    "    data = mel_extract_combined_features(file_name)\n",
    "    \n",
    "    combined_voice_features_mel.append([data, class_label])\n",
    "    \n",
    "    \n",
    "    if counter % 1000 == 0:\n",
    "        print(counter)\n",
    "    counter += 1\n",
    "\n",
    "# Convert into a Panda dataframe \n",
    "combined_voice_features_mel_df = pd.DataFrame(combined_voice_features_mel, columns=['feature','class_label'])\n",
    "\n",
    "print('Finished feature extraction from ', len(featuresdf), ' files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>class_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>[[6.6912676e-08, 1.4397854e-07, 4.937666e-07, ...</td>\n",
       "      <td>dog_bark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>[[0.03327825, 0.06925758, 0.031367134, 0.01829...</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>[[0.01548944, 0.08860275, 0.3138474, 0.2061931...</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             feature       class_label\n",
       "0  [[6.6912676e-08, 1.4397854e-07, 4.937666e-07, ...          dog_bark\n",
       "1  [[0.03327825, 0.06925758, 0.031367134, 0.01829...  children_playing\n",
       "2  [[0.01548944, 0.08860275, 0.3138474, 0.2061931...  children_playing"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_voice_features_mel_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_voice_features_mel_df_temp = combined_voice_features_mel_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_voice_features_mel_df_temp['new_feature'] = combined_voice_features_mel_df_temp.apply(lambda x: str(x['feature'].flatten().tolist()).strip('[]'),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_voice_features_mel_df_temp = combined_voice_features_mel_df_temp[['new_feature','class_label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>new_feature</th>\n",
       "      <th>class_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6.691267628866626e-08, 1.4397853931313875e-07,...</td>\n",
       "      <td>dog_bark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.03327824920415878, 0.06925757974386215, 0.03...</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.01548944041132927, 0.08860275149345398, 0.31...</td>\n",
       "      <td>children_playing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         new_feature       class_label\n",
       "0  6.691267628866626e-08, 1.4397853931313875e-07,...          dog_bark\n",
       "1  0.03327824920415878, 0.06925757974386215, 0.03...  children_playing\n",
       "2  0.01548944041132927, 0.08860275149345398, 0.31...  children_playing"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_voice_features_mel_df_temp.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_voice_features_mel_df_temp.to_csv('mel_combined_voice.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 222)"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_voice_features_mel_df['feature'][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
