{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\" />\n",
    "\n",
    "# Excel Madness Lab!\n",
    "\n",
    "_Author:_ Tim Book"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our Mission\n",
    "We work for a large supermarket chain, with stores in 10 major cities that happen to coincide with General Assembly campuses. However, this company's idea of a \"database\" is just a bunch of Excel spreadsheets! In order to analyze our data, we're going to need to process the existing data into a form we can use. **Our end goal is to have one csv per city.**\n",
    "\n",
    "## Cleanup Duty!\n",
    "It is a hard truth that data scientists spend a large majority of their time cleaning data. Data never arrives on our desks in exactly the format in which we want it, and it's up to us to transform it to a workable format.\n",
    "\n",
    "Being good cleaning, moving, and reshaping data is in itself a valuable and employable job skill. If you follow these directions exactly, we will walk through constructing an automated process for processing data from this supermarket chain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part I: Processing\n",
    "\n",
    "### Step 1: Imports and the `os` library\n",
    "We're going to import three libraries: numpy, pandas, and `os`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries here.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `os` library is extremely useful for performing system commands from within Python. Let's get two pieces of overhead out of the way now:\n",
    "\n",
    "1. Create an `output` folder using `os.mkdir()`\n",
    "2. Create a variable called `files` that is the list of files in the `data` folder using `os.listdir()`\n",
    "\n",
    "**WARNING:** The `os.mkdir()` function will give you an error if you try to make a folder that already exists!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an output folder.\n",
    "\n",
    "os.mkdir('output')\n",
    "\n",
    "# Create a files variable that contains all of our data files.\n",
    "files = os.listdir('data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Jan 23.xlsx',\n",
       " 'Jan 19.xlsx',\n",
       " 'Jan 15.xlsx',\n",
       " 'Jan 7.xlsx',\n",
       " 'Jan 6.xlsx',\n",
       " '~$Jan 1.xlsx',\n",
       " 'Jan 14.xlsx',\n",
       " 'Jan 18.xlsx',\n",
       " 'Jan 22.xlsx',\n",
       " 'Jan 29.xlsx',\n",
       " 'Jan 13.xlsx',\n",
       " 'Jan 1.xlsx',\n",
       " 'Jan 25.xlsx',\n",
       " 'Jan 24.xlsx',\n",
       " 'Jan 12.xlsx',\n",
       " 'Jan 28.xlsx',\n",
       " 'Jan 3.xlsx',\n",
       " 'Jan 11.xlsx',\n",
       " 'Jan 27.xlsx',\n",
       " 'Jan 31.xlsx',\n",
       " 'Jan 30.xlsx',\n",
       " 'Jan 26.xlsx',\n",
       " 'Jan 10.xlsx',\n",
       " 'Jan 2.xlsx',\n",
       " 'Jan 9.xlsx',\n",
       " 'Jan 21.xlsx',\n",
       " 'Jan 5.xlsx',\n",
       " 'Jan 17.xlsx',\n",
       " 'Jan 16.xlsx',\n",
       " 'Jan 4.xlsx',\n",
       " 'Jan 20.xlsx',\n",
       " 'Jan 8.xlsx']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Process one data frame\n",
    "It looks like we have data for the month of January. 31 files of 10 sheets each! Luckily they are all in the same format. So let's read just one in and process that. It might be helpful to open one up in your spreadsheet viewer of choice first (Excel, Numbers, Sheets, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['New York',\n",
       " 'Boston',\n",
       " 'Washington, DC',\n",
       " 'Atlanta',\n",
       " 'Chicago',\n",
       " 'Denver',\n",
       " 'Austin',\n",
       " 'Seattle',\n",
       " 'Los Angeles',\n",
       " 'San Francisco']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "excel_file = pd.ExcelFile('data/Jan 1.xlsx')\n",
    "excel_file.sheet_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data from your city from January 1st.\n",
    "data = pd.read_excel('data/Jan 1.xlsx',sheet_name='New York')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prodcode</th>\n",
       "      <th>price_eu</th>\n",
       "      <th>weight_kg</th>\n",
       "      <th>quantity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4159</td>\n",
       "      <td>2.048141</td>\n",
       "      <td>8.812961</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4062</td>\n",
       "      <td>2.728485</td>\n",
       "      <td>9.331372</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4404</td>\n",
       "      <td>2.182498</td>\n",
       "      <td>8.937798</td>\n",
       "      <td>491</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   prodcode  price_eu  weight_kg  quantity\n",
       "0      4159  2.048141   8.812961       138\n",
       "1      4062  2.728485   9.331372       184\n",
       "2      4404  2.182498   8.937798       491"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2a: Convert to 'Merican columns\n",
    "For whatever reason, our data are stored in euros and kilograms. Create `price_usd` and `weight_lb` columns. There are 2.2 pounds per kilogram, and 1.1 dollars per euro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['price_usd'] = data['price_eu'] * 1.1\n",
    "data['weight_lb'] = data['weight_kg'] * 2.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2b: Merge in product names\n",
    "You'll notice we also have a `plu-codes.csv` file containing actual product names matched up against their price lookup (PLU) codes. Let's merge these product names onto our Jan 1 data.\n",
    "* _Hint 1:_ What kind of merge is this? Right, left, inner, outer, etc.?\n",
    "* _Hint 2:_ Pay special attention to column names!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "plu = pd.read_csv(\"plu-codes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = data.merge(plu,how='left',left_on='prodcode',right_on='plu_code')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2c: Drop unnecessary columns\n",
    "We've created some extraneous columns. Drop the old price and weight columns, as well as any redundant columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['price_eu','weight_kg','plu_code'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2d: Add the date\n",
    "Simply create a new `date` column that is the date this data was collected. For example, if this is from `Jan 1.xlsx`, this column should be full of `Jan 1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['date'] = 'Jan 1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Write a function that conducts all of Step 2\n",
    "This function should import a **filename and a city name** and return a fully processed DataFrame. That is, the function should:\n",
    "1. Read in the data from the given file and city.\n",
    "1. Create USD and pound columns.\n",
    "1. Merge in product names.\n",
    "1. Drop unnecessary columns.\n",
    "1. Add a date column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(file, city):\n",
    "    \n",
    "    file_path = 'data/'+file\n",
    "    date = file.split('.')[0]\n",
    "    \n",
    "    data = pd.read_excel(file_path, sheet_name=city)\n",
    "    \n",
    "    data['price_usd'] = data['price_eu'] * 1.1\n",
    "    data['weight_lb'] = data['weight_kg'] * 2.2\n",
    "    data = data.merge(plu,how='left',left_on='prodcode',right_on='plu_code')\n",
    "    \n",
    "    data = data.drop(['price_eu','weight_kg','plu_code'], axis=1)\n",
    "    \n",
    "    data['date'] = date\n",
    "    \n",
    "    return data\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test your function out on a new file and city!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = process_data('Jan 2.xlsx', 'Boston')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prodcode</th>\n",
       "      <th>quantity</th>\n",
       "      <th>price_usd</th>\n",
       "      <th>weight_lb</th>\n",
       "      <th>product</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4030</td>\n",
       "      <td>109</td>\n",
       "      <td>1.974055</td>\n",
       "      <td>16.298007</td>\n",
       "      <td>Kiwi</td>\n",
       "      <td>Jan 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4796</td>\n",
       "      <td>329</td>\n",
       "      <td>2.712247</td>\n",
       "      <td>10.411764</td>\n",
       "      <td>Tomato</td>\n",
       "      <td>Jan 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4309</td>\n",
       "      <td>202</td>\n",
       "      <td>2.601073</td>\n",
       "      <td>5.135373</td>\n",
       "      <td>Lychee</td>\n",
       "      <td>Jan 2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   prodcode  quantity  price_usd  weight_lb product   date\n",
       "0      4030       109   1.974055  16.298007    Kiwi  Jan 2\n",
       "1      4796       329   2.712247  10.411764  Tomato  Jan 2\n",
       "2      4309       202   2.601073   5.135373  Lychee  Jan 2"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Process all of January's data\n",
    "For each spreadsheet, process the data and store the resulting DataFrame in one big list. **You only need to do this for your city!**\n",
    "\n",
    "* _Hint 1:_ A listcomp would make this whole step one line of code!\n",
    "* _Hint 2:_ You've already made that `files` variable to help you here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = [process_data(filename, 'New York') for filename in files ]\n",
    "# I don't know why there is a file called ~$Jan 1.xlsx exist so I need to exclude it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Concatenate all DataFrames from Step 4 into one large DataFrame\n",
    "* _Hint:_ Is there a function in `pandas` that can do something like this for us? This is also just one line of code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Jan 23.xlsx',\n",
       " 'Jan 19.xlsx',\n",
       " 'Jan 15.xlsx',\n",
       " 'Jan 7.xlsx',\n",
       " 'Jan 6.xlsx',\n",
       " '~$Jan 1.xlsx',\n",
       " 'Jan 14.xlsx',\n",
       " 'Jan 18.xlsx',\n",
       " 'Jan 22.xlsx',\n",
       " 'Jan 29.xlsx',\n",
       " 'Jan 13.xlsx',\n",
       " 'Jan 1.xlsx',\n",
       " 'Jan 25.xlsx',\n",
       " 'Jan 24.xlsx',\n",
       " 'Jan 12.xlsx',\n",
       " 'Jan 28.xlsx',\n",
       " 'Jan 3.xlsx',\n",
       " 'Jan 11.xlsx',\n",
       " 'Jan 27.xlsx',\n",
       " 'Jan 31.xlsx',\n",
       " 'Jan 30.xlsx',\n",
       " 'Jan 26.xlsx',\n",
       " 'Jan 10.xlsx',\n",
       " 'Jan 2.xlsx',\n",
       " 'Jan 9.xlsx',\n",
       " 'Jan 21.xlsx',\n",
       " 'Jan 5.xlsx',\n",
       " 'Jan 17.xlsx',\n",
       " 'Jan 16.xlsx',\n",
       " 'Jan 4.xlsx',\n",
       " 'Jan 20.xlsx',\n",
       " 'Jan 8.xlsx']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat = pd.concat(df_list,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prodcode</th>\n",
       "      <th>quantity</th>\n",
       "      <th>price_usd</th>\n",
       "      <th>weight_lb</th>\n",
       "      <th>product</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4650</td>\n",
       "      <td>109</td>\n",
       "      <td>1.330281</td>\n",
       "      <td>17.027600</td>\n",
       "      <td>Mushroom</td>\n",
       "      <td>Jan 23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4011</td>\n",
       "      <td>206</td>\n",
       "      <td>1.857675</td>\n",
       "      <td>7.891258</td>\n",
       "      <td>Banana</td>\n",
       "      <td>Jan 23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4796</td>\n",
       "      <td>416</td>\n",
       "      <td>2.666518</td>\n",
       "      <td>20.348500</td>\n",
       "      <td>Tomato</td>\n",
       "      <td>Jan 23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   prodcode  quantity  price_usd  weight_lb   product    date\n",
       "0      4650       109   1.330281  17.027600  Mushroom  Jan 23\n",
       "1      4011       206   1.857675   7.891258    Banana  Jan 23\n",
       "2      4796       416   2.666518  20.348500    Tomato  Jan 23"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_concat.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Do this for all cities, write data\n",
    "Here's the big one. For each city, process and the data as in steps 3-5, and then write the data to our `output` folder. Below is a dictionary of city name to desired output file name.\n",
    "\n",
    "Before writing your DataFrame, do the following:\n",
    "* Add a `city` column\n",
    "* Reorder the columns into the following order:\n",
    "\n",
    "\n",
    "| city | date | product | prodcode | quantity | weight_lb | price_usd |\n",
    "|---|---|---|---|---|---|---|\n",
    "\n",
    "* _Hint:_ You can reorder DataFrame columns simply by writing over your DataFrame with itself, but specifying the specific column order with `.loc`. For example:\n",
    "\n",
    "`print(df)`\n",
    "\n",
    "| b | c | a |\n",
    "|---|---|---|\n",
    "| 1 | 2 | 3 |\n",
    "\n",
    "`df = df.loc[:, [\"a\", \"b\", \"c\"]]`\n",
    "\n",
    "`print(df)`\n",
    "\n",
    "| a | b | c |\n",
    "|---|---|---|\n",
    "| 3 | 1 | 2 |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_dict = {\n",
    "    \"Atlanta\": \"atl.csv\",\n",
    "    \"Austin\": \"atx.csv\",\n",
    "    \"Boston\": \"bos.csv\",\n",
    "    \"Chicago\": \"chi.csv\",\n",
    "    \"Denver\": \"den.csv\",\n",
    "    \"Los Angeles\": \"lax.csv\",\n",
    "    \"New York\": \"nyc.csv\",\n",
    "    \"San Francisco\": \"sf.csv\",\n",
    "    \"Seattle\": \"sea.csv\",\n",
    "    \"Washington, DC\": \"dc.csv\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through city_dict and carry out Step 6 here.\n",
    "# The keys of city_dict can serve as the sheet name.\n",
    "# The values of city_dict are what you should name the output .csv files.\n",
    "# If done correctly, this cell could take almost a minute to run!\n",
    "\n",
    "for city in city_dict:\n",
    "    file_name = city_dict[city]\n",
    "    final_path = 'output/'+file_name\n",
    "    \n",
    "    list_df = [process_data(filename, city) for filename in files if not filename.startswith('~')]\n",
    "    concat_df = pd.concat(list_df,ignore_index=True)\n",
    "    concat_df['city'] = city\n",
    "    \n",
    "    concat_df = concat_df.loc[:,['city','date','product','prodcode','quantity','weight_lb','price_usd']]\n",
    "    \n",
    "    concat_df.to_csv(final_path,index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II: Checking our answers \n",
    "In steps very similar to the ones conducted above...\n",
    "1. Loop through the files we just wrote to `output`, and read them in, collecting them all in one list\n",
    "1. Combine all of those DataFrames into one large DataFrame\n",
    "1. For each city, find the mean `quantity`, `weight_lb`, and `price_usd`.\n",
    "\n",
    "If you've done everything correct, your answer should look exactly like this:\n",
    "\n",
    "![](imgs/correct-output.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_files = os.listdir('output/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_city = pd.concat([pd.read_csv(f'output/{filename}') for filename in output_files if not filename.startswith('.')],ignore_index=True)\n",
    "# there is a hidden file was created automatically, so I need to ignore it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_city.groupby('city')['quantity','weight_lb','price_usd'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part III (BONUS): Get this process production-ready!\n",
    "_This part of the lab is optional, but very highly recommended, as the skills developed in this part are extremely common in industry._\n",
    "\n",
    "For this step, we're going to take this whole process and put it into a production-ready Python script. **ABSOLUTELY NONE OF THIS STEP SHOULD TAKE PLACE IN A JUPYTER NOTEBOOK! PRODUCTIONALIZED ETL (_\"Extract, Transform, Load\"_) CODE DOES NOT TAKE PLACE IN A JUPYTER NOTEBOOK!**\n",
    "\n",
    "The instructions are simple: As conducted in this lab, read, transform, and export the data in our Excel files into .csv files. The code should be in a `.py` file and executable from the command line. Here are some hints and tips to guide you:\n",
    "\n",
    "### Hints, tips, and tricks:\n",
    "* A good place to start is with the code you've already written. In this notebook, you can click `File > Download as > Python (.py)` to export as a `.py` file. Most of this exercise then comes down to you cleaning this file. (There will be a lot to clean).\n",
    "* Remember `os.mkdir()` will throw an error if the folder you're trying to make already exists. Maybe you should check to see if it already exists. If it already exists, what should you do? (Remember that `.csv` can be overwritten with no problem.) The functions that can help you with this are all in the `os` library.\n",
    "* Remember to follow all of the Python best practices we've already learned:\n",
    "    - All import statements should go at the top of your script.\n",
    "    - Comment your code. Comments shouldn't explain _what_ code does, but _why_ the code does this.\n",
    "    - Keep your code DRY (don't repeat yourself) as opposed to WET (write everything twice). All constants should be variables that only need to be changed once. All code should be bottled into functions so you only need to fix it once.\n",
    "* Make sure not to hardcode \"Jan\" anywhere. The point is that this code can be run throughout the lifetime of this supermarket's project, which is likely months or years. Keep your code so that if you get February data, you only need to change one tiny piece of the script (probably a file path)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
