{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Simple Linear Regression with Sacramento Real Estate Data\n",
    "\n",
    "_Authors: Matt Brems, Sam Stack, Justin Pounders_\n",
    "\n",
    "---\n",
    "\n",
    "In this lab you will hone your exploratory data analysis (EDA) skills and practice constructing simple linear regressions using a data set on Sacramento real estate sales.  The data set contains information on qualities of the property, location of the property, and time of sale."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Read in the Sacramento housing data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sac_csv = './datasets/sacramento_real_estate_transactions.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Conduct exploratory data analysis on this data set. \n",
    "\n",
    "**Report any notable findings here and any steps you take to clean/process data.**\n",
    "\n",
    "> **Note:** These EDA checks should be done on every data set you handle. If you find yourself checking repeatedly for missing/corrupted data, it might be beneficial to have a function that you can reuse every time you're given new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_**Fun Fact:** Zip codes often have leading zeros — e.g., 02215 = Boston, MA — which will often get knocked off automatically by many software programs like Python or Excel. You can imagine that this could create some issues. _"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Our goal will be to predict price. List variables that you think qualify as predictors of price in an SLR model. \n",
    "\n",
    "**For each of the variables you believe to be a valid potential predictor in an SLR model, generate a plot showing the relationship between the independent and dependent variables.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you've finished cleaning or have made a good deal of progress cleaning, it's always a good idea to save your work.\n",
    "```python\n",
    "shd.to_csv('./datasets/sacramento_real_estate_transactions_Clean.csv')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Which variable would be the best predictor of Y in an SLR model? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Build a function that will take in two lists, `Y` and `X`, and return the intercept and slope coefficients that minimize SSE. \n",
    "\n",
    "`Y` is the target variable and `X` is the predictor variable.\n",
    "\n",
    "- **Test your function on price and the variable you determined was the best predictor in Problem 4.**\n",
    "- **Report the slope and intercept.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Interpret the intercept. Interpret the slope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Give an example of how this model could be used for prediction and how it could be used for inference. \n",
    "\n",
    "**Be sure to make it clear which example is associated with prediction and which is associated with inference.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8: [Bonus] Using the model you came up with in Problem 5, calculate and plot the residuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> The material following this point can be completed after the second lesson on Monday.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dummy Variables\n",
    "\n",
    "---\n",
    "\n",
    "It is important to be cautious with categorical variables, which represent distict groups or categories, when building a regression. If put in a regression \"as-is,\" categorical variables represented as integers will be treated like *continuous* variables.\n",
    "\n",
    "That is to say, instead of group \"3\" having a different effect on the estimation than group \"1\" it will estimate literally 3 times more than group 1. \n",
    "\n",
    "For example, if occupation category \"1\" represents \"analyst\" and occupation category \"3\" represents \"barista\", and our target variable is salary, if we leave this as a column of integers then barista will always have `beta*3` the effect of analyst.\n",
    "\n",
    "This will almost certainly force the beta coefficient to be something strange and incorrect. Instead, we can re-represent the categories as multiple \"dummy coded\" columns.\n",
    "\n",
    "### 9. Use the `pd.get_dummies` function to convert the `type` column into dummy-coded variables.\n",
    "\n",
    "Print out the header of the dummy-coded variable output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### A Word of Caution When Creating Dummies\n",
    "\n",
    "Let's touch on precautions we should take when dummy coding.\n",
    "\n",
    "**If you convert a qualitative variable to dummy variables, you want to turn a variable with N categories into N-1 variables.**\n",
    "\n",
    "> **Scenario 1:** Suppose we're working with the variable \"sex\" or \"gender\" with values \"M\" and \"F\". \n",
    "\n",
    "You should include in your model only one variable for \"sex = F\" which takes on 1 if sex is female and 0 if sex is not female! Rather than saying \"a one unit change in X,\" the coefficient associated with \"sex = F\" is interpreted as the average change in Y when sex = F relative to when sex = M.\n",
    "\n",
    "| Female | Male | \n",
    "|-------|------|\n",
    "| 0 | 1 | \n",
    "| 1 | 0 |\n",
    "| 0 | 1 |\n",
    "| 1 | 0 |\n",
    "| 1 | 0 |\n",
    "_As we can see a 1 in the female column indicates a 0 in the male column. And so, we have two columns stating the same information in different ways._\n",
    "\n",
    "> Scenario 2: Suppose we're modeling revenue at a bar for each of the days of the week. We have a column with strings identifying which day of the week this observation occured in.\n",
    "\n",
    "We might include six of the days as their own variables: \"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\". **But not all 7 days.**  \n",
    "\n",
    "|Monday | Tuesday | Wednesday | Thursday | Friday | Saturday | \n",
    "|-------|---------|-----------|----------|--------|----------|\n",
    "| 1     | 0       |0          |      0   |0       | 0        | \n",
    "| 0     | 1       |0          |      0   |0       | 0        | \n",
    "| 0     | 0       |1          |      0   |0       | 0        | \n",
    "| 0     | 0       |0          |      1   |0       | 0        | \n",
    "| 0     | 0       |0          |      0   |1       | 0        | \n",
    "| 0     | 0       |0          |      0   |0       | 1        | \n",
    "| 0     | 0       |0          |      0   |0       | 0        | \n",
    "\n",
    "_As humans we can infer from the last row that if its is not Monday, Tusday, Wednesday, Thursday, Friday or Saturday than it must be Sunday. Models work the same way._\n",
    "\n",
    "The coefficient for Monday is then interpreted as the average change in revenue when \"day = Monday\" relative to \"day = Sunday.\" The coefficient for Tuesday is interpreted in the average change in revenue when \"day = Tuesday\" relative to \"day = Sunday\" and so on.\n",
    "\n",
    "The category you leave out, which the other columns are *relative to* is often referred to as the **reference category**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Remove \"Unkown\" from four dummy coded variable dataframe and append the rest to the original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Build what you think may be the best MLR model predicting `price`. \n",
    "\n",
    "The independent variables are your choice, but *include at least three variables.* At least one of which should be a dummy-coded variable (either one we created before or a new one).\n",
    "\n",
    "To construct your model don't forget to load in the statsmodels api:\n",
    "\n",
    "```python\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_I'm going to engineer a new dummy variable for 'HUGE houses'.  Those whose square footage is 3 (positive) standard deviations away from the mean._\n",
    "```\n",
    "Mean = 1315\n",
    "STD = 853\n",
    "Huge Houses > 3775 sq ft\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. Plot the true price vs the predicted price to evaluate your MLR visually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13. List the five assumptions for an MLR model. \n",
    "\n",
    "Indicate which ones are the same as the assumptions for an SLR model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SLR AND MLR**:  \n",
    "\n",
    "- *Linearity: Y must have an approximately linear relationship with each independent X_i.*\n",
    "- *Independence: Errors (residuals) e_i and e_j must be independent of one another for any i != j.*\n",
    "- *Normality: The errors (residuals) follow a Normal distribution.*\n",
    "- *Equality of Variances: The errors (residuals) should have a roughly consistent pattern, regardless of the value of the X_i. (There should be no discernable relationship between X_1 and the residuals.)*\n",
    "\n",
    "**MLR ONLY**:  \n",
    "- *Independence Part 2: The independent variables X_i and X_j must be independent of one another for any i != j*\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14. Pick at least two assumptions and articulate whether or not you believe them to be met  for your model and why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15. [Bonus] Generate a table showing the point estimates, standard errors, t-scores, p-values, and 95% confidence intervals for the model you built. \n",
    "\n",
    "**Write a few sentences interpreting some of the output.**\n",
    "\n",
    "> **Hint:** scikit-learn does not have this functionality built in, but statsmodels does in the `summary` method.  To fit the statsmodels model use something like the following.  There is one big caveat here, however!  `statsmodels.OLS` does _not_ add an intercept to your model, so you will need to do this explicitly by adding a column filled with the number 1 to your X matrix\n",
    "\n",
    "```python\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# The Default here is Linear Regression (ordinary least squares regression OLS)\n",
    "model = sm.OLS(y,X).fit()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "> The material following this point can be completed after the first lesson on Tuesday.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 16. Regression Metrics\n",
    "\n",
    "Implement a function called `r2_adj()` that will calculate $R^2_{adj}$ for a model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 17. Metrics, metrics, everywhere...\n",
    "\n",
    "Write a function to calculate and print or return six regression metrics.  Use other functions liberally, including those found in `sklearn.metrics`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 18. Model Iteration\n",
    "\n",
    "Evaluate your current home price prediction model by calculating all six regression metrics.  Now adjust your model (e.g. add or take away features) and see how to metrics change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 19. Bias vs. Variance\n",
    "\n",
    "At this point, do you think your model is high bias, high variance or in the sweet spot?  If you are doing this after Wednesday, can you provide evidence to support your belief?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
